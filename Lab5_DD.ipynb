{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8cbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a42f91",
   "metadata": {},
   "source": [
    "Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f33964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  pd.read_csv('Train/X_train.txt',sep=' ', header=None)\n",
    "X_test = pd.read_csv('Test/X_test.txt',sep=' ', header=None)\n",
    "Y_train = pd.read_csv('Train/y_train.txt',sep=' ', header=None)\n",
    "Y_test = pd.read_csv('Test/y_test.txt',sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4341a697",
   "metadata": {},
   "source": [
    "Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1892ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "                    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rforest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f76bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8bbbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(\n",
    "    estimators=[('dt', dtree), ('rf', rforest), ('svm', svm)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a218a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'F1': make_scorer(f1_score, average = 'macro')\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8d49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tworzę dataframe\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame(columns=['type', 'algorithm', 'measure', 'value'])\n",
    "df2 = pd.DataFrame(columns=['type', 'algorithm', 'measure', 'value'])\n",
    "df3 = pd.DataFrame(columns=['type', 'algorithm', 'measure', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484cf09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.8363617227751161 (+/-0.024390639208381814)\n",
      "Decision Tree recall: 0.7030083927539738 (+/-0.039216577895608305)\n",
      "Decision Tree F1 score: 0.6902032937683946 (+/-0.029064668739987917)\n",
      "Decision Tree AUC score: nan (+/-nan)\n",
      "\n",
      "Random Forest accuracy: 0.9075608217913433 (+/-0.014680178601439917)\n",
      "Random Forest recall: 0.805835334540058 (+/-0.0291162099096642)\n",
      "Random Forest F1 score: 0.81192409962421 (+/-0.02944819969074095)\n",
      "Random Forest AUC score: nan (+/-nan)\n",
      "\n",
      "SVM accuracy: 0.9190214315133826 (+/-0.019589132226909587)\n",
      "SVM recall: 0.8114758668854369 (+/-0.04057554167897378)\n",
      "SVM F1 score: 0.817971683011731 (+/-0.03245542881804215)\n",
      "SVM AUC score: nan (+/-nan)\n",
      "\n",
      "Ensemble accuracy: 0.9065299776825855 (+/-0.016861233037959757)\n",
      "Ensemble recall: 0.7961947276293837 (+/-0.031880066046625244)\n",
      "Ensemble F1 score: 0.8062540935699566 (+/-0.0271829975297122)\n",
      "Ensemble AUC score: nan (+/-nan)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.836362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.703008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.690203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.907561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.805835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.811924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.919021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.811476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.817972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.906530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.796195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.806254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type      algorithm    measure     value\n",
       "0  Ensemble_learning  Decision Tree   accuracy  0.836362\n",
       "0  Ensemble_learning  Decision Tree     recall  0.703008\n",
       "0  Ensemble_learning  Decision Tree   F1 score  0.690203\n",
       "0  Ensemble_learning  Decision Tree  AUC score       NaN\n",
       "0  Ensemble_learning  Random Forest   accuracy  0.907561\n",
       "0  Ensemble_learning  Random Forest     recall  0.805835\n",
       "0  Ensemble_learning  Random Forest   F1 score  0.811924\n",
       "0  Ensemble_learning  Random Forest  AUC score       NaN\n",
       "0  Ensemble_learning            SVM   accuracy  0.919021\n",
       "0  Ensemble_learning            SVM     recall  0.811476\n",
       "0  Ensemble_learning            SVM   F1 score  0.817972\n",
       "0  Ensemble_learning            SVM  AUC score       NaN\n",
       "0  Ensemble_learning       Ensemble   accuracy  0.906530\n",
       "0  Ensemble_learning       Ensemble     recall  0.796195\n",
       "0  Ensemble_learning       Ensemble   F1 score  0.806254\n",
       "0  Ensemble_learning       Ensemble  AUC score       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for clf, label in zip([dtree, rforest, svm, eclf], ['Decision Tree', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_validate(clf, X_train, Y_train, scoring=scoring, cv=5)\n",
    "    \n",
    "    #uzupełniam linijkę\n",
    "    df1 = df1.append(pd.DataFrame([[\"Ensemble_learning\", label, \"accuracy\", scores['test_accuracy'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "    print(\"{} accuracy: {} (+/-{})\".format(label,scores['test_accuracy'].mean(),scores['test_accuracy'].std()))\n",
    "    df1 = df1.append(pd.DataFrame([[\"Ensemble_learning\", label, \"recall\", scores['test_recall'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))    \n",
    "    print(\"{} recall: {} (+/-{})\".format(label,scores['test_recall'].mean(),scores['test_recall'].std()))\n",
    "    df1 = df1.append(pd.DataFrame([[\"Ensemble_learning\", label, \"F1 score\", scores['test_F1'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))    \n",
    "    print(\"{} F1 score: {} (+/-{})\".format(label,scores['test_F1'].mean(),scores['test_F1'].std()))\n",
    "    scores = cross_val_score(clf, X_train, Y_train, scoring='roc_auc', cv=5)\n",
    "    df1 = df1.append(pd.DataFrame([[\"Ensemble_learning\", label, \"AUC score\", scores.mean()]], columns=['type', 'algorithm', 'measure', 'value']))    \n",
    "    print(\"{} AUC score: {} (+/-{})\".format(label, scores.mean(), scores.std()))\n",
    "    print(\"\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e87c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(\"ensemble_learning.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3a4a9",
   "metadata": {},
   "source": [
    "Zad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d441fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae64101",
   "metadata": {},
   "outputs": [],
   "source": [
    "svmBC = BaggingClassifier(svm)\n",
    "dtreeBC = BaggingClassifier(dtree)\n",
    "rforestBC = BaggingClassifier(rforest)\n",
    "\n",
    "eclfBC = VotingClassifier(\n",
    "    estimators=[('dt', dtreeBC), ('rf', rforestBC), ('svm', svmBC)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75553e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.8702248564450754 (+/-0.022673459956525678)\n",
      "Decision Tree recall: 0.7723628323864163 (+/-0.029152933729561927)\n",
      "Decision Tree F1 score: 0.7798760007906931 (+/-0.03037585507839258)\n",
      "Decision Tree AUC score: nan (+/-nan)\n",
      "\n",
      "Random Forest accuracy: 0.909235498031377 (+/-0.015558572610885398)\n",
      "Random Forest recall: 0.7891016445535073 (+/-0.04207778561148863)\n",
      "Random Forest F1 score: 0.7912932341726375 (+/-0.045883657302332)\n",
      "Random Forest AUC score: nan (+/-nan)\n",
      "\n",
      "SVM accuracy: 0.9185062166388631 (+/-0.018998172339784496)\n",
      "SVM recall: 0.8132568750079494 (+/-0.025488389014395405)\n",
      "SVM F1 score: 0.8138184995450729 (+/-0.016270221960777227)\n",
      "SVM AUC score: nan (+/-nan)\n",
      "\n",
      "Ensemble accuracy: 0.9085919973878763 (+/-0.018335597568312805)\n",
      "Ensemble recall: 0.8012122113113985 (+/-0.03313513705834565)\n",
      "Ensemble F1 score: 0.8099393724840975 (+/-0.02904175548593534)\n",
      "Ensemble AUC score: nan (+/-nan)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([dtreeBC, rforestBC, svmBC, eclfBC], ['Decision Tree', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_validate(clf, X_train, Y_train, scoring=scoring, cv=5)\n",
    "    df2 = df2.append(pd.DataFrame([[\"BaggingClassifier\", label, \"accuracy\", scores['test_accuracy'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "    df2 = df2.append(pd.DataFrame([[\"BaggingClassifier\", label, \"recall\", scores['test_recall'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "    df2 = df2.append(pd.DataFrame([[\"BaggingClassifier\", label, \"F1 score\", scores['test_F1'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "    print(\"{} accuracy: {} (+/-{})\".format(label,scores['test_accuracy'].mean(),scores['test_accuracy'].std()))\n",
    "    print(\"{} recall: {} (+/-{})\".format(label,scores['test_recall'].mean(),scores['test_recall'].std()))\n",
    "    print(\"{} F1 score: {} (+/-{})\".format(label,scores['test_F1'].mean(),scores['test_F1'].std()))\n",
    "    scores = cross_val_score(clf, X_train, Y_train, scoring='roc_auc', cv=5)\n",
    "    print(\"{} AUC score: {} (+/-{})\".format(label, scores.mean(), scores.std()))\n",
    "    df2 = df2.append(pd.DataFrame([[\"BaggingClassifier\", label, \"AUC score\", scores.mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa24f5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.870225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.772363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.779876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.789102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.791293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.918506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.813257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.813818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.908592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.801212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.809939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type      algorithm    measure     value\n",
       "0  BaggingClassifier  Decision Tree   accuracy  0.870225\n",
       "0  BaggingClassifier  Decision Tree     recall  0.772363\n",
       "0  BaggingClassifier  Decision Tree   F1 score  0.779876\n",
       "0  BaggingClassifier  Decision Tree  AUC score       NaN\n",
       "0  BaggingClassifier  Random Forest   accuracy  0.909235\n",
       "0  BaggingClassifier  Random Forest     recall  0.789102\n",
       "0  BaggingClassifier  Random Forest   F1 score  0.791293\n",
       "0  BaggingClassifier  Random Forest  AUC score       NaN\n",
       "0  BaggingClassifier            SVM   accuracy  0.918506\n",
       "0  BaggingClassifier            SVM     recall  0.813257\n",
       "0  BaggingClassifier            SVM   F1 score  0.813818\n",
       "0  BaggingClassifier            SVM  AUC score       NaN\n",
       "0  BaggingClassifier       Ensemble   accuracy  0.908592\n",
       "0  BaggingClassifier       Ensemble     recall  0.801212\n",
       "0  BaggingClassifier       Ensemble   F1 score  0.809939\n",
       "0  BaggingClassifier       Ensemble  AUC score       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2914c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel(\"aggregating.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea855ab1",
   "metadata": {},
   "source": [
    "Zad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ca14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5ac4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABoost accuracy: 0.5249137924604763 (+/-0.004247544189137631)\n",
      "ADABoost recall: 0.3104606305543187 (+/-0.022355561035529423)\n",
      "ADABoost F1 score: 0.24022021234303376 (+/-0.020232598059393935)\n",
      "ADABoost AUC score: nan (+/-nan)\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "label='ADABoost'\n",
    "scores = cross_validate(ada, X_train, Y_train, scoring=scoring, cv=5)\n",
    "df3 = df3.append(pd.DataFrame([[\"AdaBoostClassifier\", label, \"accuracy\", scores['test_accuracy'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "df3 = df3.append(pd.DataFrame([[\"AdaBoostClassifier\", label, \"recall\", scores['test_recall'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "df3 = df3.append(pd.DataFrame([[\"AdaBoostClassifier\", label, \"F1 score\", scores['test_F1'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "\n",
    "print(\"{} accuracy: {} (+/-{})\".format(label,scores['test_accuracy'].mean(),scores['test_accuracy'].std()))\n",
    "print(\"{} recall: {} (+/-{})\".format(label,scores['test_recall'].mean(),scores['test_recall'].std()))\n",
    "print(\"{} F1 score: {} (+/-{})\".format(label,scores['test_F1'].mean(),scores['test_F1'].std()))\n",
    "scores = cross_val_score(clf, X_train, Y_train, scoring='roc_auc', cv=5)\n",
    "print(\"{} AUC score: {} (+/-{})\".format(label, scores.mean(), scores.std()))\n",
    "df3 = df3.append(pd.DataFrame([[\"AdaBoostClassifier\", label, \"AUC score\", scores.mean()]], columns=['type', 'algorithm', 'measure', 'value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "361361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.5249137924604763 (+/-0.004247544189137631)\n",
      "XGBoost recall: 0.3104606305543187 (+/-0.022355561035529423)\n",
      "XGBoost F1 score: 0.24022021234303376 (+/-0.020232598059393935)\n",
      "XGBoost AUC score: nan (+/-nan)\n"
     ]
    }
   ],
   "source": [
    "xgb = xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "label = 'XGBoost'\n",
    "scores = cross_validate(ada, X_train, Y_train, scoring=scoring, cv=5)\n",
    "df3 = df3.append(pd.DataFrame([[\"XGBoost\", label, \"accuracy\", scores['test_accuracy'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "df3 = df3.append(pd.DataFrame([[\"XGBoost\", label, \"recall\", scores['test_recall'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "df3 = df3.append(pd.DataFrame([[\"XGBoost\", label, \"F1 score\", scores['test_F1'].mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "print(\"{} accuracy: {} (+/-{})\".format(label,scores['test_accuracy'].mean(),scores['test_accuracy'].std()))\n",
    "print(\"{} recall: {} (+/-{})\".format(label,scores['test_recall'].mean(),scores['test_recall'].std()))\n",
    "print(\"{} F1 score: {} (+/-{})\".format(label,scores['test_F1'].mean(),scores['test_F1'].std()))\n",
    "scores = cross_val_score(clf, X_train, Y_train, scoring='roc_auc', cv=5)\n",
    "df3 = df3.append(pd.DataFrame([[\"XGBoost\", label, \"AUC score\", scores.mean()]], columns=['type', 'algorithm', 'measure', 'value']))\n",
    "print(\"{} AUC score: {} (+/-{})\".format(label, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dca63fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.524914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.310461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.240220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.524914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.310461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.240220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type algorithm    measure     value\n",
       "0  AdaBoostClassifier  ADABoost   accuracy  0.524914\n",
       "0  AdaBoostClassifier  ADABoost     recall  0.310461\n",
       "0  AdaBoostClassifier  ADABoost   F1 score  0.240220\n",
       "0  AdaBoostClassifier  ADABoost  AUC score       NaN\n",
       "0             XGBoost   XGBoost   accuracy  0.524914\n",
       "0             XGBoost   XGBoost     recall  0.310461\n",
       "0             XGBoost   XGBoost   F1 score  0.240220\n",
       "0             XGBoost   XGBoost  AUC score       NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5e7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_excel(\"boosting.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582f65a",
   "metadata": {},
   "source": [
    "Zad 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbbe4c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>measure</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.836362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.703008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.690203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.907561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.805835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.811924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.919021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.811476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.817972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>SVM</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.906530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.796195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.806254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble_learning</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.870225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.772363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.779876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.909235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.789102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.791293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.918506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.813257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.813818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>SVM</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.908592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.801212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.809939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.524914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.310461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.240220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>ADABoost</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.524914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.310461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>0.240220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>AUC score</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type      algorithm    measure     value\n",
       "0   Ensemble_learning  Decision Tree   accuracy  0.836362\n",
       "0   Ensemble_learning  Decision Tree     recall  0.703008\n",
       "0   Ensemble_learning  Decision Tree   F1 score  0.690203\n",
       "0   Ensemble_learning  Decision Tree  AUC score       NaN\n",
       "0   Ensemble_learning  Random Forest   accuracy  0.907561\n",
       "0   Ensemble_learning  Random Forest     recall  0.805835\n",
       "0   Ensemble_learning  Random Forest   F1 score  0.811924\n",
       "0   Ensemble_learning  Random Forest  AUC score       NaN\n",
       "0   Ensemble_learning            SVM   accuracy  0.919021\n",
       "0   Ensemble_learning            SVM     recall  0.811476\n",
       "0   Ensemble_learning            SVM   F1 score  0.817972\n",
       "0   Ensemble_learning            SVM  AUC score       NaN\n",
       "0   Ensemble_learning       Ensemble   accuracy  0.906530\n",
       "0   Ensemble_learning       Ensemble     recall  0.796195\n",
       "0   Ensemble_learning       Ensemble   F1 score  0.806254\n",
       "0   Ensemble_learning       Ensemble  AUC score       NaN\n",
       "0   BaggingClassifier  Decision Tree   accuracy  0.870225\n",
       "0   BaggingClassifier  Decision Tree     recall  0.772363\n",
       "0   BaggingClassifier  Decision Tree   F1 score  0.779876\n",
       "0   BaggingClassifier  Decision Tree  AUC score       NaN\n",
       "0   BaggingClassifier  Random Forest   accuracy  0.909235\n",
       "0   BaggingClassifier  Random Forest     recall  0.789102\n",
       "0   BaggingClassifier  Random Forest   F1 score  0.791293\n",
       "0   BaggingClassifier  Random Forest  AUC score       NaN\n",
       "0   BaggingClassifier            SVM   accuracy  0.918506\n",
       "0   BaggingClassifier            SVM     recall  0.813257\n",
       "0   BaggingClassifier            SVM   F1 score  0.813818\n",
       "0   BaggingClassifier            SVM  AUC score       NaN\n",
       "0   BaggingClassifier       Ensemble   accuracy  0.908592\n",
       "0   BaggingClassifier       Ensemble     recall  0.801212\n",
       "0   BaggingClassifier       Ensemble   F1 score  0.809939\n",
       "0   BaggingClassifier       Ensemble  AUC score       NaN\n",
       "0  AdaBoostClassifier       ADABoost   accuracy  0.524914\n",
       "0  AdaBoostClassifier       ADABoost     recall  0.310461\n",
       "0  AdaBoostClassifier       ADABoost   F1 score  0.240220\n",
       "0  AdaBoostClassifier       ADABoost  AUC score       NaN\n",
       "0             XGBoost        XGBoost   accuracy  0.524914\n",
       "0             XGBoost        XGBoost     recall  0.310461\n",
       "0             XGBoost        XGBoost   F1 score  0.240220\n",
       "0             XGBoost        XGBoost  AUC score       NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.concat([df1, df2, df3])\n",
    "df1.to_excel(\"comparison.xlsx\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebeca36",
   "metadata": {},
   "source": [
    "Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236441c5",
   "metadata": {},
   "source": [
    "1. Uczenie zespołowe pozwala zmaksymalizować korzyści z możliwości korzystania z różnych algorytmów. Niemniej należy pamiętać, że choć takie postępowanie może być bardzo korzystne pod kątem jakości końcowego modelu, to moc obliczeniowa potrzebna na zrealizowanie takiego podejścia jest bardzo duża. W związku z tym należy stwierdzić, że uczenie zespołowe warto wykorzystywać przy rozwiązywaniu złożonych problemów.\n",
    "2. Do uczenia zespołowego warto wykorzystywać takie miary oceny jakości modeli, jak np. accuracy, recall, f1 score czy auc score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e472e",
   "metadata": {},
   "source": [
    "Autorzy: Jakub Bembnista i Walter Modrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dadce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
